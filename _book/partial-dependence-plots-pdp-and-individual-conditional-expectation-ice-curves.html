<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 2 Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) Curves | Limitations of Interpretable Machine Learning Methods</title>
  <meta name="description" content="Situations in which PDP, ALE, LIME, LOCO and feature importance fail.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 2 Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) Curves | Limitations of Interpretable Machine Learning Methods" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Situations in which PDP, ALE, LIME, LOCO and feature importance fail." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) Curves | Limitations of Interpretable Machine Learning Methods" />
  
  <meta name="twitter:description" content="Situations in which PDP, ALE, LIME, LOCO and feature importance fail." />
  

<meta name="author" content="">


<meta name="date" content="2019-05-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="accumulated-local-effects-ale.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Limitations of ML Interpretability</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html"><a href="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html"><i class="fa fa-check"></i><b>2</b> Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) Curves</a><ul>
<li class="chapter" data-level="2.1" data-path="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html"><a href="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html#partial-dependence-plots-pdp"><i class="fa fa-check"></i><b>2.1</b> Partial Dependence Plots (PDP)</a></li>
<li class="chapter" data-level="2.2" data-path="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html"><a href="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves.html#individual-conditional-expectation-curves"><i class="fa fa-check"></i><b>2.2</b> Individual Conditional Expectation Curves</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html"><i class="fa fa-check"></i><b>3</b> Accumulated Local Effects (ALE)</a><ul>
<li class="chapter" data-level="3.1" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#motivation"><i class="fa fa-check"></i><b>3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#the-theoretical-formula"><i class="fa fa-check"></i><b>3.2</b> The Theoretical Formula</a><ul>
<li class="chapter" data-level="3.2.1" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#centering"><i class="fa fa-check"></i><b>3.2.1</b> Centering</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#estimation-formula"><i class="fa fa-check"></i><b>3.3</b> Estimation Formula</a><ul>
<li class="chapter" data-level="3.3.1" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#implementation-formula"><i class="fa fa-check"></i><b>3.3.1</b> Implementation Formula</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="accumulated-local-effects-ale.html"><a href="accumulated-local-effects-ale.html#intuition-and-interpretation"><i class="fa fa-check"></i><b>3.4</b> Intuition and Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>4</b> Feature Importance</a><ul>
<li class="chapter" data-level="4.1" data-path="feature-importance.html"><a href="feature-importance.html#permutation-feature-importance-pfi"><i class="fa fa-check"></i><b>4.1</b> Permutation Feature Importance (PFI)</a></li>
<li class="chapter" data-level="4.2" data-path="feature-importance.html"><a href="feature-importance.html#leave-one-covariate-out-loco"><i class="fa fa-check"></i><b>4.2</b> Leave-One-Covariate-Out (LOCO)</a></li>
<li class="chapter" data-level="4.3" data-path="feature-importance.html"><a href="feature-importance.html#interpretability-of-feature-importance-and-its-limitations"><i class="fa fa-check"></i><b>4.3</b> Interpretability of Feature Importance and its Limitations</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="local-interpretable-model-agnostic-explanations.html"><a href="local-interpretable-model-agnostic-explanations.html"><i class="fa fa-check"></i><b>5</b> Local Interpretable Model-Agnostic Explanations</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Limitations of Interpretable Machine Learning Methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="partial-dependence-plots-pdp-and-individual-conditional-expectation-ice-curves" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) Curves</h1>
<div id="partial-dependence-plots-pdp" class="section level2">
<h2><span class="header-section-number">2.1</span> Partial Dependence Plots (PDP)</h2>
<p>The Partial Dependence Plot (PDP) is a rather intuitive and easy-to-understand visualization of the features’ impact on the predicted outcome. It maps the marginal effect of the selected variable(s) and can reveal the nature of dependence structure between target and individual feature variable.</p>
<p>The underlying function can be described as follows:</p>
<p>Let <span class="math inline">\(x_S\)</span> be the set of features of interest for the PDP and <span class="math inline">\(x_C\)</span> the complement set which contains all other features.
While the general model function <span class="math inline">\(f(x) = f(x_S, x_C)\)</span> depends on all input variables, the partial dependence function marginalizes over the feature distribution in set C :</p>
<p><span class="math display">\[f_{x_S}(x_S) = \mathbb{E}_{x_C}[f(x_S, x_C)]\]</span></p>
<p>The partial dependence function can be estimated by averaging the actual feature values of <span class="math inline">\(x_C\)</span> in the training data at given values of <span class="math inline">\(x_S\)</span> or, in other words, it computes the marginal effect of <span class="math inline">\(x_S\)</span> on the prediction. In order to derive realistic results, a major assumption of the PDP is that the features in <span class="math inline">\(x_S\)</span> and <span class="math inline">\(x_C\)</span> are independent and thus uncorrelated.</p>
<p><span class="math display">\[\hat{f}_{x_S}(x_S)=\frac{1}{n}\sum_{i=1}^{n}f(x_S, x^{(i)}_{C})\]</span></p>
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="images/age_pdp.jpeg" alt="The PDP shows that the survival probability is sharply dropping until age 18 and more moderately afterwards." width="90%" />
<p class="caption">
FIGURE 2.1: The PDP shows that the survival probability is sharply dropping until age 18 and more moderately afterwards.
</p>
</div>
<p>In classification problems with probability outputs, the partial dependence function is modeled separately for all of the K different classes, i.e. it shows the probability for each respective class at given feature values of <span class="math inline">\(x_S\)</span>.</p>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="images/pdp_class.jpeg" alt="The classification PDP reveals that passengers in lower classes had a lower probability to survive than those in a higher class." width="90%" />
<p class="caption">
FIGURE 2.2: The classification PDP reveals that passengers in lower classes had a lower probability to survive than those in a higher class.
</p>
</div>
<p><strong>Advantages and Limitations of Partial Dependence Plots</strong></p>
<p>Partial Dependence Plots are easy to compute and a poular way to explain insights from black box Machine Learning models. With their intuitive character, PDPs perfectly qualify for the communication to non-technical audience. However, due to limited visualization techniques and the restriction of human perception to a maximum of three dimensions, only one or two features can reasonably be displayed in one PDP.</p>
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="images/pdp_2_features_1.jpeg" alt="The two-dimensional PDP for the numerical feature Age and the categorical feature Sex shows that while the survival probability for both genders declines as age increases, that there is a difference between genders an that the decrease is much steeper for males." width="100%" />
<p class="caption">
FIGURE 2.3: The two-dimensional PDP for the numerical feature Age and the categorical feature Sex shows that while the survival probability for both genders declines as age increases, that there is a difference between genders an that the decrease is much steeper for males.
</p>
</div>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="images/pdp_2_features_2.jpeg" alt="The two-dimensional PDP for the numerical features Age and Fare illustrates that survival probability of younger passengers is fairly uniform, whilke from age 20 onwards, passengers travelling at a lower fare also had a much lower probability to survive than those that paid a high fare." width="100%" />
<p class="caption">
FIGURE 2.4: The two-dimensional PDP for the numerical features Age and Fare illustrates that survival probability of younger passengers is fairly uniform, whilke from age 20 onwards, passengers travelling at a lower fare also had a much lower probability to survive than those that paid a high fare.
</p>
</div>
<p>Drawing a PDP with one or two feature variables allows a straight-forward interpretation of the marginal effects. This holds true as long as the features are not correlated. Should this assumption be violated, the partial dependence function will produce unrealistic data points. Furthermore, opposite effects of heterogeneous subgroups might remain hidden through averaging the marginal effects, which could lead to wrong conclusions.</p>
</div>
<div id="individual-conditional-expectation-curves" class="section level2">
<h2><span class="header-section-number">2.2</span> Individual Conditional Expectation Curves</h2>
<p>While the partial dependence plots provide the average effect of a feature, the Individual Conditional Expectation (ICE) plots disaggregate this average and plot the functional relationship between the predicted response and the feature for individual instances. Thus, a PDP is the average of the lines of an ICE plot.</p>
<p>A formal definition: consider the response function <span class="math inline">\(\hat{f}\)</span>, for each instance in <span class="math inline">\({(x^{(i)}_S, x^{(i)}_C)}^N_{i=1}\)</span>, the curve <span class="math inline">\(\hat{f}_S^{(i)}\)</span> is plotted against the observed values of <span class="math inline">\(x^{(i)}_S\)</span>, while <span class="math inline">\(x^{(i)}_C\)</span> remains fixed.</p>
<p>In ICE plots, each line represents separately one instance and shows what would happen to the model’s prediction if the feature of a particular instance varied, holding all other features the same (c.p.). An ICE plot can highlight the variation in the fitted values across the range of a feature. This suggests where and to what extent heterogeneities might exist.</p>
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="images/ice_plot.jpeg" alt="The ICE plot indicates that there is underlying heterogeneity in the complement set." width="80%" />
<p class="caption">
FIGURE 2.5: The ICE plot indicates that there is underlying heterogeneity in the complement set.
</p>
</div>
<p>###Centered ICE Plot###
Heterogeneity in the model can be difficult to distinguish when the curves have a wide range of intercepts and “stacked” on each other. The so called centered ICE plot (c-ICE) is a simple solution which removes level effects. The curves are centered at a certain point in the feature and display only the difference in the prediction to this point.  After anchoring a location <span class="math inline">\(x^a\)</span> in the range of <span class="math inline">\(x_s\)</span> and connecting all prediction lines at that point, the new curves are defined as:</p>
<p><span class="math display">\[\hat{f}^{(i)}_{cent} = \hat{f^{(i)}} - \mathbf{1}\hat{f}(x^a,x^{(i)}_C)\]</span>
It is recommended that the most interpretable plots occur when the minimum or the maximum observed value is chosen.</p>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="images/c_ice_plot.jpeg" alt="Centered ICE plot." width="80%" />
<p class="caption">
FIGURE 2.6: Centered ICE plot.
</p>
</div>
<p>###Derivative ICE Plot###
Another way to explore the heterogeneity is to show plots of the partial derivative
of <span class="math inline">\(\hat{f}\)</span> with respect to <span class="math inline">\(x_s\)</span>. Assume that <span class="math inline">\(x_s\)</span> does not interact
with the other predictors in the fitted model, the prediction function can be written as:</p>
<p><span class="math display">\[\hat{f}(x) = \hat{f}(x_s,x_C) = g(x_s) + h(x_C),\]</span></p>
<p>so that <span class="math display">\[\frac{\partial{\hat{f}(\mathbf{x})}}{\partial x_s} = g&#39;(x_s)\]</span></p>
<p>When no interactions are present in the fitted model, all curves in the d-ICE plot are equivalent, and the plot shows a single line. When interactions do exist, the derivative lines will be heterogeneous. As it can be difficult to visually assess derivatives from ICE plots, it is useful to plot an estimate of the partial derivative directly.</p>
<p>###Advantages and Limitations of ICE Plots###
<strong>Advantages</strong>
ICE plots are more intuitive than PDPs and enable data scientists to drill much deeper to explore individual differences and identify subgroups and interactions between model inputs.</p>
<p><strong>Disadvantages</strong>
Firstly, only one feature can be plotted in an ICE plot meaningfully. Otherwise, there will be a problem of overplotting and you would see nothing. Secondly, ICE plots have the same problem as PDPs that some data points in the lines might be invalid. Finally, it might be difficult to see to average in ICE plots.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="accumulated-local-effects-ale.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/compstat-lmu/iml_methods_limitations/edit/master/01-pdp.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub", "book.mobi"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
