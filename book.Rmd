--- 
title: "Limitations of Interpretable Machine Learning Methods"
author: ""
date: "`r Sys.Date()`"
documentclass: krantz
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: False 
lof: False
site: bookdown::bookdown_site
description: "Situations in which PDP, ALE, LIME, LOCO and feature importance fail."
graphics: yes
cover-image: images/cover.png
---

```{r setup, include=FALSE}
options(
  htmltools.dir.version = FALSE, formatR.indent = 2, width = 55, digits = 4
)
output <- knitr::opts_knit$get("rmarkdown.pandoc.to")
is.html = !is.null(output) && output == "html"
```

# Preface {-}

```{r cover, cache=FALSE, out.width="500", fig.align="center", echo=FALSE, eval = is.html}
knitr::include_graphics('images/cover.png')
```

This book explains limitations of current methods in interpretable machine learning.
The methods include partial dependence plots (PDP), Accumulated Local Effects (ALE), permutation feature importance, leave-one-covariate out (LOCO) and local interpretable model-agnostic explanations (LIME).
All of those methods can be used to explain the behavior and predictions of trained machine learning models.
But the interpretation methods might not work well in the following cases:

- if a model models interactions (e.g. when a random forest is used)
- if features strongly correlate with each other
- if the model does not correctly model causal relationships
- if parameters of the interpretation method are not set correctly

This book is the outcome of the seminar "Limitations of Interpretable Machine Learning" which took place in summer 2019 at the Department of Statistics, LMU Munich.

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)

![Creative Commons License](images/by-nc-sa.png)

This book is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).


\mainmatter

# Foreword {-}

*Author: Christoph Molnar*

<!-- An experiment -->
This book is the result of an experiment in university teaching.
Each semester, students of the Statistics Master can choose from a selection of seminar topics.
Usually, every student in the seminar chooses a scientific paper, gives a talk about the paper and summarizes it in the form of a seminar paper.
The supervisors help the students, they listen to the talks, read the seminar papers, grade the work and then ... hide the seminar papers away in (digital) drawers.
This seemed wasteful to us, given the huge amount of effort the students usually invest in seminars.
An idea was born:
Why not create a book with a website as the outcome of the seminar?
Something that will last at least a few years after the end of the semester.
In the summer term 2019, some Statistics Master students signed up for our seminar entitled "Limitations of Interpretable Machine Learning".
When they came to the kick-off meeting, they had no idea that they would write a book by the end of the semester.

We were bound by the examination rules for conducting the seminar, but otherwise we could deviate from the traditional format.
We deviated in several ways:

1. Each student project is part of a book, and not an isolated seminar paper.
1. We gave challenges to the students, instead of papers. The challenge was to investigate a specific limitation of interpretable machine learning methods.
1. We designed the work to live beyond the seminar.
1. We emphasized collaboration. Students wrote some chapters in teams and reviewed each others texts.

<!-- Our experience -->
Looking back, the seminar was a lot of fun and -- from our perspective -- successful.
Especially considering that it was an experiment.
Everyone was highly motivated and we got great feedback from the students that they liked the format.
For the students it was a more work than a traditional seminar.
But in the end, our hope is that their effort will pay off for them as well, not only because of their increased visibility.
It was also more work for us supervisors.
But the extra effort was worth it, since limitations of interpretability are relevant for our research.
For me the seminar was an inspiration.
The students had new ideas and new perspectives to approach the limitations of interpretable machine learning.

<!-- Technical setup -->
## Technical Setup {-}
The book chapters are written in the Markdown language.
The simulations, data examples and visualizations were created with R [@rlang].
To combine R-code and Markdown, we used rmarkdown.
The book was compiled with the bookdown package.
We collaborated using git and github.
For details, head over to the [book's repository](https://github.com/compstat-lmu/iml_methods_limitations).



<!--chapter:end:index.Rmd-->


# Introduction

Placeholder


## Statistical Modeling: The Two Approaches
## Importance of Interpretability
## Interpretable Machine Learning
## Outline of the booklet

<!--chapter:end:00-introduction.Rmd-->


# Introduction to Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE)  {#pdp}

Placeholder


## Partial Dependence Plots (PDP)
### Advantages and Limitations of Partial Dependence Plots
## Individual Conditional Expectation Curves
### Centered ICE Plot
### Derivative ICE Plot
### Advantages and Limitations of ICE Plots

<!--chapter:end:01-00-pdp.Rmd-->


# PDP and Correlated Features {#pdp-correlated}

Placeholder


## Problem Description {#ProblemDescription}
### What is the issue with dependent features?
### What is the issue with extrapolation? 
## Dependent Features: Bike Sharing Dataset {#RealData}
### Dependency between Numerical Features 
### Dependency between Categorical Features
### Dependency between Numerical and Categorical Features {#NumCat}
## Dependent Features: Simulated Data {#SimulatedData}
### Simulation Settings: Numerical Features
### Simulation of Setting 1: Linear Dependence
#### PDPs based on Linear Model
#### PDPs based on Random Forest
#### PDPs based on Support Vector Machines
### Simulation of Setting 2: Nonlinear Dependence
#### PDPs based on Random Forest
#### PDPs based on Support Vector Machines
### Simulation of Setting 3: Missing informative feature $x_3$
#### PDPs based on Linear Model
#### PDPs based on Random Forest
#### PDPs based on Support Vector Machines
### Simulation Settings: Categorical Features
#### PDPs based on Linear Model
#### PDPs based on Random Forest
#### PDPs based on Support Vector Machines
## Extrapolation Problem: Simulation {#ExtrapolationProblem}
### Simulation based on established learners {#ExtrapolationProblemEstablished}
### Simulation based on own prediction function {#ExtrapolationProblemPrediction}
## Summary

<!--chapter:end:01-1-pdp-correlated.Rmd-->


# PDP and Causal Interpretation {#pdp-causal}

Placeholder


## Introduction
## Motivation  
## Causal Interpretability: Interventions and Directed Acyclical Graphs
## Scenarios
## Conclusion

<!--chapter:end:01-3-pdp-causal.Rmd-->


# Introduction to Accumulated Local Effects (ALE) {#ale}

Placeholder


## Motivation
## The Theoretical Formula {#ale-intro-formula}
### Centering
## Estimation Formula 
### Implementation Formula
## Intuition and Interpretation {#ale-intro-interpret}

<!--chapter:end:02-00-ale.Rmd-->


# Comparison of ALE and PDP {#ale-pdp}

Placeholder


## Comparison one feature
### Example 1: Multiplicative prediction function
### Example 2: Additive prediction function
## Comparison two features
### The 2D ALE
#### Theoretical Formula 2D ALE
#### Estimation 2D ALE
#### Example 1 continued - Theoretical and estimated 2D ALE
### 2D ALE vs 2D PDP
#### Example 2 - 2D comparison
#### Example 1 - 2D comparison
#### Example 1 modified - 2D comparison
## Runtime comparison 
### One numerical feature of interest
### Two numerical features of interest
### One categorial feature of interest
## Comparison for unevenly distributed data - Example 4: Munich rents
## Appendix
### Calculation of theoretical 2D ALE example {#ale-2d-example-calculation}

<!--chapter:end:02-4-ale-pdp.Rmd-->


# ALE Intervals, Piece-Wise Constant Models and Categorical Features {#ale-misc}

Placeholder


## How to choose the number and/or length of the intervals
### State of the art
### ALE Approximations 
### Example 1: additive feature effects
### Example 2: multiplicative feature effects
### Example 3: Unbalanced datasets and shaky prediction functions
## Problems with piece-wise constant models
### Outlook 
## Categorical Features
### Ordering the features
### Estimation of the ALE
### Example of ALE with categorical feature  
### Interpretation
### Changes of the ALE due to different orders
### Conclusion

<!--chapter:end:02-5-ale-other.Rmd-->


# Introduction to Feature Importance {#pfi}

Placeholder


## Permutation Feature Importance (PFI)
## Leave-One-Covariate-Out (LOCO)
## Interpretability of Feature Importance and its Limitations

<!--chapter:end:03-00-feature-importance.Rmd-->


# PFI, LOCO and Correlated Features {#pfi-correlated}

Placeholder


## Effect on Feature Importance by Adding Correlated Features
### Simulation 
### Real Data
## Alternative Measures Dealing with Correlated Features
## Summary 
## Note to the reader

<!--chapter:end:03-6-fi-correlated.Rmd-->


# Partial and Individual Permutation Feature Importance {#pfi-partial}

Placeholder


## Preliminaries on Partial and Individual Conditional Importance {#ch2}
## Simulations: A cookbook for using with PI and ICI {#ch3}
### Detect Interactions {#ch31}
#### Partial Importance and Individual Conditional Importance plots {#ch311}
#### d-ICI (derivative Individual Conditional Importance) {#ch312}
### Explain Interactions {#ch32}
#### Drivers for Heterogeneity in Feature Importance {#ch321}
#### Conditional Importance plots {#ch322}
### Stress Methods in a Non-Linear Relationship Setting {#ch323}
## Real Data Application: Boston Housing {#ch4}
## Discussion {#ch5}

<!--chapter:end:03-7-pfi-ici.Rmd-->


# PFI: Training vs. Test Data {#pfi-data}

Placeholder


## Introduction to Test vs. Training Data
## Theoretical Discussion for Test and Training Data
## Reaction to model behavior
### Gradient Boosting Machines
### Data sets used for calculations
### Results
### Interpretation of the results
## Summary

<!--chapter:end:03-8-fi-training-test.Rmd-->


# Introduction to Local Interpretable Model-Agnostic Explanations (LIME) {#lime}

Placeholder


## Local Surrogate Models and LIME
## How LIME works in detail
### Neighbourhood
### What makes a good explainer?
### Sampling and perturbation
## Example
## Outlook

<!--chapter:end:04-00-lime.Rmd-->


# LIME and Neighbourhood {#lime-neighbor}

Placeholder


## The Neighbourhood in LIME in more detail {#id2}
## The problem in a one-dimensional setting {#id3}
## The problem in more complex settings {#id4}
### Simulated data {#id41}
#### Global Linear Relationships {#id411}
#### Local Linear Relationships {#id412}
#### Global Non-Linearity {#id413}
### Real data {#id42}
## Discussion and outlook {#id5}
## Note to the reader {#id6}
### Packages used {#id61}
### How we used the lime R package and why {#id62}

<!--chapter:end:04-09-lime-neighbourhood.Rmd-->


# LIME and Sampling {#lime-sample}

Placeholder


## Understanding sampling in LIME
### Formula
### Sampling strategies
#### Categorical features
#### Numerical features
### Visualization of a basic example
## Sketching Problems of Sampling
## Real World Problems with LIME
### Boston Housing Data
#### Mean point versus outlying point
#### Decision tree versus linear regression model
#### Kernel density estimation versus binning
### Rental Bikes Data
#### Majority data point versus minority data point
#### Decision tree versus linear regression model
## Experiments regarding Sampling stability
### Influence of feature dimension
#### Feature dimension - setup
#### Feature dimension - results
#### Amount of features selected - setup
#### Amount of features selected - results
### Influence of sample size
#### Sample size -- results
### Influence of black-box
#### Black-box -- setup
#### Black-box -- results
#### Black-box overfit -- setup
#### Black-box overfit -- results
## Outlook
## Conclusion

<!--chapter:end:04-10-lime-sampling.Rmd-->

# Acknowledgements

The most important contributions are from the students themselves.
The success of such projects highly depends on the students.
And this book is a success, so thanks a lot to all the authors!
The other important role is the supervisor.
Thanks to all the supervisors who participated!
Special thanks to [Bernd Bischl](https://www.compstat.statistik.uni-muenchen.de/people/bischl/) who enabled us to conduct the seminar in such an experimental way, supported us and gave valuable feedback for the seminar structure.
Thanks a lot as well to the entire [Department of Statistics](https://www.statistik.uni-muenchen.de/) and the [LMU Munich](http://www.en.uni-muenchen.de/index.html) for the infrastructure.

This work has been partially supported by the Bavarian State Ministry of Science and the Arts in the framework of the Centre Digitisation.Bavaria (ZD.B) and by the German Federal Ministry of Education and Research (BMBF) under Grant No. 01IS18036A.
The authors of this work take full responsibilities for its content.



<!--chapter:end:08-acknowledgements.Rmd-->

`r if (knitr:::is_html_output()) '# References {-}'`

```{r include=FALSE}
# generate a BibTeX database automatically for some R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```


<!--chapter:end:99-references.Rmd-->

