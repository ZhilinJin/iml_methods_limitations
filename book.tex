\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Limitations of Interpretable Machine Learning Methods},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Limitations of Interpretable Machine Learning Methods}
\date{2019-05-20}

\begin{document}
\maketitle

% you may need to leave a few empty pages before the dedication page

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}

\begin{center}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}


This project explains the limitations of current approaches in interpretable machine learning, such as partial dependence plots (PDP, Accumulated Local Effects (ALE), permutation feature importance, leave-one-covariate out (LOCO) and local interpretable model-agnostic explanations (LIME).
All of those methods can be used to explain the behavior and predictions of trained machine learning models.
The interpretation methods might not work well in the following cases:

\begin{itemize}
\tightlist
\item
  if a model models interactions (e.g.~when a random forest is used)
\item
  if features strongly correlate with each other
\item
  if the model does not correctly model causal relationships
\item
  if parameters of the interpretation method are not set correctly
\end{itemize}

\hypertarget{structure-of-the-book}{%
\section*{Structure of the book}\label{structure-of-the-book}}


TODO

\mainmatter

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

Here is some text

\hypertarget{this-is-a-smaller-title}{%
\section{This is a smaller title}\label{this-is-a-smaller-title}}

We have a nice figure in Figure \ref{fig:hello}, and also a table in Table \ref{tab:iris}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{.1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(cars, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.9\linewidth]{book_files/figure-latex/hello-1} \caption{Hello World!}\label{fig:hello}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
  \KeywordTok{head}\NormalTok{(iris), }\DataTypeTok{caption =} \StringTok{'The boring iris data.'}\NormalTok{,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:iris}The boring iris data.}
\centering
\begin{tabular}{rrrrl}
\toprule
Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\
\midrule
5.1 & 3.5 & 1.4 & 0.2 & setosa\\
4.9 & 3.0 & 1.4 & 0.2 & setosa\\
4.7 & 3.2 & 1.3 & 0.2 & setosa\\
4.6 & 3.1 & 1.5 & 0.2 & setosa\\
5.0 & 3.6 & 1.4 & 0.2 & setosa\\
\addlinespace
5.4 & 3.9 & 1.7 & 0.4 & setosa\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{partial-dependence-plots-pdp-and-individual-conditional-expectation-curves}{%
\chapter{Partial Dependence Plots (PDP) and Individual Conditional Expectation Curves}\label{partial-dependence-plots-pdp-and-individual-conditional-expectation-curves}}

\hypertarget{partial-dependence-plots}{%
\section{Partial Dependence Plots}\label{partial-dependence-plots}}

\hypertarget{ice}{%
\section{ICE}\label{ice}}

\hypertarget{accumulated-local-effects-ale}{%
\chapter{Accumulated Local Effects (ALE)}\label{accumulated-local-effects-ale}}

\hypertarget{feature-importance}{%
\chapter{Feature Importance}\label{feature-importance}}

As in previous chapters already discussed, there exist a variety of methods that enable a better understanding of the relationship between features and the outcome variables, especially for complex machine learning models. For instance, Partial Dependence (PD) plots visualize the feature effects on a global, aggregated level, whereas Individual Conditional Expectation (ICE) plots unravel the average feature effect by analyzing individual observations, allowing to detect, if existing, any heterogeneous relationships. Yet, these methods do not provide any insights to what extent a feature contributes to the predictive power of a model - in the following defined as feature importance. This perspective becomes interesting when recalling that so far black-box machine learning models aim for predictive accuracy rather than for inference, and hence, it is persuasive to also establish agnostic-methods that focus on the performance dimension. In the following, the two most common approaches, Permutation Feature Importance (PFI) by \citet{breiman2001random} and Leave-One-Covariate-Out (LOCO) by \citet{lei2018distribution}, for calculating and visualizing a Feature Importance metric, are introduced. At this point, however, it is worth to clarify that the concepts of feature effects and feature importance can by no means be ranked but rather should be considered as mutual complements that enable the interpretability from different angles. After introducing the concepts of PFI and LOCO, a brief discussion of their interpretability but also its non-negligible limitations will follow.

\hypertarget{permutation-feature-importance-pfi}{%
\section{Permutation Feature Importance (PFI)}\label{permutation-feature-importance-pfi}}

The concept of Permutation Feature Importance was first introduced by \citet{breiman2001random} and applied on a random forest model. The main principle is rather straightforward and easily implemented. The idea is as follows: When permuting the values of feature \(j\), its explanatory power mitigates, as it breaks the association to the outcome variable \(y\). Therefore, if the model relied on the feature \(j\), the prediction error \(e = L(y,f(X))\) of the model \(f\) should increase when predicting with the ``permuted feature'' dataset \(X_{perm}\) instead of with the ``initial feature'' dataset \(X_{orig}\). The importance of feature \(j\) is then evaluated by the increase of the prediction error which can be either determined by taking the difference \(e_{perm} - e_{orig}\) or taking the ratio \(e_{perm}/e_{orig}\). Note, taking the ratio can be favorable when comparing the result across different models. A feature is considered less important, if the increase in the prediction error was comparably small and the opposite if the increase was large. Thereby, it is important to note that when calculating the prediction error based on the permuted features there is no need to retrain the model \(f\). Below, a respective PFI algorithm based on \citet{fisher2018model} is outlined. Note however, that their original algorithm has a slightly different specification and was adjusted here for general purposes.

\textbf{The Permutation Feature Importance algorithm based on Fisher, Rudin, and Dominici (2018):}

Input: Trained model \(f\), feature matrix \(X\), target vector \(y\), error measure \(L(y,f(X))\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate the original model error \(e_{orig} = L(y,f(X))\) (e.g mean squared error)
\item
  For each feature \(j = 1,...,p\) do:

  \begin{itemize}
  \tightlist
  \item
    Generate feature matrix \(x_{perm}\) by permuting feature j in the data \(X\)
  \item
    Estimate error \(e_{perm} = L(y,f(X_{perm}))\) based on the predictions of the permuted data,
  \item
    Calculate permutation feature importance \(PFI_{j} = e_{perm}/e_{orig}\). Alternatively, the difference can be used: \(PFI_{j} = e_{perm} - e_{orig}\)
  \end{itemize}
\item
  Sort features by descending FI.
\end{enumerate}

Below, it is illustrated, by a fictional, exemplary random forest model, how the permutation algorithm alters the original dataset. For each of the \(M\) trees, the respectively permuted dataset is then used to first predict the outcomes and then calculate the prediction error. From the resulting differences in the prediction errors \(\Delta e^{i}\), the average \(\frac{1}{M}\sum_{i=1}^{M} \Delta e_{1}^{i} = PFI_{1}\) over all trees is calucated which can then be considered as the PFI of feature \(j\).

\includegraphics{Permutation_0.jpg}

\includegraphics{Permutation_1.jpg}
\ldots{}\ldots{}
\includegraphics{Permutation_2.jpg}

~

\(\hspace{0.5cm}\Delta e^{(1)} = L(y,f^{(1)}(X))- L(y,f^{(1)}(X_{\text{perm}}))\hspace{1.9cm}\Delta e^{(M)} = L(y,f^{(M)}(X))- L(y,f^{(M)}(X_{\text{perm}}))\)

To show, how the PFI for all features of a model can be visualized and thereby more conveniently compared, the PFI algorithm with a random forest model is applied on the dataset ``mtcars'', which is available in R. To predict the gasoline consumption (miles per gallone), ten variables are included, whereby as the results show, the PFIs vary substantially across the variables. The depicted points correspond to the mean PFIs over all random forest iterations and the boundaries of the bands illustrate the 0.05- and 0.95-quantiles, respectively.

\includegraphics{book_files/figure-latex/unnamed-chunk-1-1.pdf}

\hypertarget{leave-one-covariate-out-loco}{%
\section{Leave-One-Covariate-Out (LOCO)}\label{leave-one-covariate-out-loco}}

The concept of Leave-One-Covariate-Out (LOCO) is as already mentioned a different approach to PFI with the same objective, to gain insights on the importance of a specific feature for the prediction performance of a model. Although applications of LOCO exist, where comparable to PFI, the initial values of feature \(j\) are replaced by its mean, median or zero \citep[see][]{hall2017ideas}, and hence, circumvent the disadvantage of re-training the model \(f\), the common approach follows the idea to simply leave the respective feature out. The overall prediction error of the re-trained model \(f_{-j}\) is then compared to the prediction error resulted from the baseline model. However, re-training the model results in higher computational costs, becoming more severe with an increasing feature space. The pseudo-code shown below, illustrates the algorithm for the common case where the feature is left out. \citep[see][]{lei2018distribution}

\textbf{The Leave-One-Covariate-Out algorithm based on Lei et al.~(2018):}

Input: Trained model \(f\), feature matrix \(X\), target vector \(y\), error measure \(L(y,f(X))\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate the original model error \(e_{orig} = L(y,f(X))\) (e.g mean squared error)
\item
  For each feature \(j = 1,...,p\) do:

  \begin{itemize}
  \tightlist
  \item
    Generate feature matrix \(x_{-j}\) by removing feature j in the data \(X\)
  \item
    Refit model \(f_{-j}\) with data \(X_{-j}\)
  \item
    Estimate error \(e_{-j} = L(y,f_{-j}(X_{-j}))\) based on the predictions of the reduced data,
  \item
    Calculate LOCO Feature Importance \(FI_{j} = e_{-j}/e_{orig}\). Alternatively, the difference can be used: \(FI_{j} = e_{-j} - e_{orig}\)
  \end{itemize}
\item
  Sort features by descending FI.
\end{enumerate}

Below, it is shown, how the LOCO algorithm alters the original dataset, whereby it always differs, depending on the respective feature that is left out. Note, that the qualititative and quantitative interpretations correspond the ones from the PFI method. So do the visualization tools and therefore at this point it is refrained from providing the reader with an additonal real data example.

\includegraphics{LOCO_1.JPG}

\(L(y,f(X))- L(y,f_{-1}(X_{-1}) = \text{Feature Importance of }x_{1}\)

\ldots{}

\includegraphics{LOCO_2.JPG}

\(L(y,f(X) - L(y,f_{-p}(X_{-p})) = \text{Feature Importance of } x_{p}\)

\hypertarget{interpretability-of-feature-importance-and-its-limitations}{%
\section{Interpretability of Feature Importance and its Limitations}\label{interpretability-of-feature-importance-and-its-limitations}}

After both methods are discussed, the question to what extent these agnostic-methods can contribute to a more comprehensive interpretability of machine learning models will be now touched on. By doing so, it is necessary to also reflect upon the limitations of the model regarding the interpretability of the results. The latter will constitute the main focus in the following chapters.
Conveniently, both methods are highly adaptable on whether using classification or regression models, as they are non-rigid towards the prediction error metric (e.g.~Accuracy, Precision, Recall, AUC, Average Log Loss, Mean Absolute Error, Mean Squared Error etc.). This allows to assess Feature Importance based on different performance measures. Besides, the interpretation can be conducted on a high-level, as both concepts and do consider neither the shape of the relationship between feature and outcome variable nor the direction of the feature effect. However, as illustrated in Figure XX, PFI and LOCO only return for each feature a single number and thereby neglect possible variations between subgroups in the data. Chapter XX will focus on how this limitation can be, at least for PFI, circumvented and introduces the concepts of Partial Importance (PI) and Individual Conditional Importance (ICI) which both avail themselves on the conceptual ideas of PD and ICE. Besides, limitations appear when some features in the feature space are correlated. If so, simply breaking the relationship between a feature and the outcome variable does not necessarily reveal the true Feature Importance as the explanatory power is shifted to the remaining, correlated feature, resulting in a weakened drop in the model performance. This can also result in an erroneous ranking and hence, in incorrect conclusions. Further, if correlation exists and only in case of applying the PFI method, permuting a feature can result in unrealistic data instances so that the model performance is evaluated based on data which is never observed in reality. This makes comparisons of prediction errors complicated and therefore it should always be checked for this problem, if applying the PFI method. Chapter XX will focus on this limitation by comparing the performance of PFI and LOCO for different models (e.g.~linear models or random forest) and different levels of correlation in the data. Beyond these limitations, it is evident to also question whether these agnostic-meethods should be computed on training or test data. As answering that, depends highly on the research question and data, it is refrained to go in more detail at this point but will be examined and further discussed in chapter XX.

\hypertarget{local-interpretable-model-agnostic-explanations}{%
\chapter{Local Interpretable Model-agnostic Explanations}\label{local-interpretable-model-agnostic-explanations}}

  \bibliography{book.bib,packages.bib}

\backmatter
\printindex

\end{document}
