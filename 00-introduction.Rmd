# Introduction (work in progress)


## Statistical Modeling: The Two Approaches
* Data Modeling Approach
* Algorithmic Modeling Approach
* Historical Development
* Machine Learning
* Information Criterion

In statistics there are two approaches to reach conclusions from Data. First, the data modeling approach, where one assumes that the data are generated by a given stochastic data model. More specifically, a proposed model associates the input variables, random noise and parameters with the response variables. Typical models are for instance the linear and logistic regression model. These models allow to predict what the responses are going to be to future input variables and give information on how the response variables and input variables are associated, i.e. they are interpretable.  
Second, the algorithmic modeling approach that uses algorithmic models and treats the underlying data mechanism as unknown. More precisely, the goal is to find an algorithm that operates on the input variables to predict the response variables. Algorithms that are used are for instance random forests and neural nets. These algorithms allow to predict what the responses are going to be to future input variables, but do not give information on how the response variables and input variables are associated. Put differently, these algorithms produce black box models, because they do not provide any direct explanation for their predictions.

Within the statistics community the data modeling approach was prevalently dominant for a long time. However, especially in the last decade the increasing availability of enormous amounts of complex and unstructured data as well as the increase in processing power of computers served as a breeding ground for a strong shift to the algorithmic modeling approach, primarily for two reasons.  
First, the data modeling approach is not applicable to exciting problems like text, speech and image recognition. Second, for complex prediction problems new algorithms such as random forests and neural nets outperform classical models in prediction accuracy as they can model complex relationships in the data. 
For these reasons, more and more researchers switched from the data modeling approach to the algorithmic modeling approach that is much more common under the name machine learning.  
But what about the interpretability? As we learned in the first paragraph machine learning algorithms are black box models that do not provide any direct explanation for their predictions. Hence, the questions arises whether we need to know why an algorithm makes a certain prediction? To get a better feeling for this question it's helpful to understand how algorithms learn to make predictions and for which tasks machine learning is used in industry and academia.

## Importance of Interpretability
* How do algorithms learn
* Use cases in academia
* Uses cases in industry
* Summary
 

## Interpretable Machine Learning
* Definition
* Example
* Unterteilung (model agnostic etc.)
* Ãœberleitung zu Limitations


## Outline of the booklet
* Methods
* Limitations 


