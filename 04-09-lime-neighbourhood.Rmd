---
output:
  html_document: default
  pdf_document: default
---
# LIME and Neighbourhood

*Author: Philipp Kopper*

This section will discuss the effect of the neighbourhood on LIME's explanations.
This is very critical for tabular data.
Hence, we will limit ourselves to the analysis of tabular data for the remainder of this chapter.

As described in the previous chapter, LIME aims to create local surrogate models for each observation to be explained.
These local models operate in the proximity or _neighbourhood_ of the instance to be explained.
They are fit based on weights which indicate their proximity to the observation to be explained.
The weights are typically determined using kernels that transform the proximity measure.

The proper parametrisation of the kernel is an obvious issue.
However, this issue exists in any approach that uses kernels, such as kernel density estimations.
Figure \@ref(fig:fig1) illustrates kernel densities from a standard normal distribution.

```{r, fig1, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "The appropriate kernel width for kernel density estimations."}
knitr::include_graphics("images/04-09-01.png")
```

One can easily see that the first panel seems to be appropriate while the second one is too granular.
The proper definition of the neighbourhood is very crucial in this case.
However, with no prior information, this definition is arbitrary.
We can only judge on the proper definition of the neighbourhood from our experience and our expectations.
This may work in low dimensional problems and descriptive statistics.
However, machine learning models operate in multivariate space and mostly tackle complex associations.
Thus, it seems much harder to argue on the proper neighbourhood definition when working with LIME.

This chapter reviews the neighbourhood issue w.r.t. the LIME algorithm critically.
The objective of this chapter is more to outline this particular issue and not to suggest solutions for it.
First of all, it describes the neighbourhood definition abstractly in greater detail. 
Then, it illustrates how problematic the neighbourhood definition is in a simple one-dimensional example.
Furthermore, we study the effect of altering the kernel size more systematically in more complex contexts in the next section.
The first subsection investigates multivariate globally linear relationships.
The second one researches local coefficients.
The third one studies non-linear effects.
Afterward, we apply the insights from simulated data to a real data set and suggest best practises for setting an appropriate kernel width when working with LIME.


## The Neighbourhood in LIME in more detail


When obtaining explanations with LIME the neighbourhood of an instance is determined when fitting the model by applying weights to instances w.r.t. proximity to the instance of interest.
However, it is important to note that this step is already arbitrary.
@craven1996 show that increasing the density of observations around the instance of interest is very helpful to achieve model fidelity.
This could be obtained in many more ways than weighting observations as done in LIME.
One possible alternative might be to combine steps 2 (sampling) and 4 (weighting) of the LIME algorithm.
This way we would increase the density around the instance already by proper sampling. 
In fact, @laugel2018defining claim that this way should be preferred over the way LIME samples.
In this chapter, however, we focus on the explicit implementation in LIME and analyse how the weighting strategy _ceteris paribus_ affects surrogate model stability.

When working with LIME, the weighting of instances is performed using a kernel function over the distances of instances to the instance of interest.
This leaves us two _arbitrary_ (in fact they may not be _that_ arbitrary) choices:
the distance and the kernel function.
Typical distance functions applicable to statistical data analysis are based on the L0, L1 and L2 norms.
For numerical features, one tends to use either manhattan distance (L1) or euclidean distance (L2).
For categorical features one would classically apply hamming distance (L0).
For mixed data (data with both categorical and numerical features), one usually one combines distances for numerical and categorical features.
So does Gower's distance @gower1986metric (new??) or a bit more general the distance proposed by @huang1998kproto

$$ d_H(x_i, x_j) = d_{euc}(x_i, x_j) + \lambda d_{ham}(x_i, x_j) $$

with $d_{euc}$ referring to the euclidean distance and $d_{ham}$ to the hamming distance.
$d_{euc}$ is only computed for numerical and $d_{ham}$ only for categorical ones.
$\lambda$ steers the importance of categorical features relative to numerical ones.
@huang1998kproto recommends setting $\lambda$ to equal to the average standard deviation of the numerical features.
For scaled numerical features (standard deviation is one) this means that $d_H = d_{euc}$ if categorical features are one-hot-encoded.
However, it is important to note that despite these measures it may be challenging to properly determine distances for mixed data properly. 
@ribeiro2016should recommend using cosine distance for text and
Euclidean distance for images.

For the kernel function itself, there are two hyperparameters to be set.
First of all the type of kernel.
Second, the kernel width.
By default, the R implementation implements an exponential kernel where the kernel width equals the square root of the number of features.

As the choice of the distance measure seems least arbitrary and the choice of the kernel function is not expected to have a crucial impact on the neighbourhood definition, we focus on the kernel width in our experimental study.
However, it is very important to notice that practically the distance measure may interact with the kernel width.
This is because as of July 2019 the current implementation in R Gower distance does not apply any kernel as it already returns scaled distances.
We observed that this may have some undesired properties as global models seem to be preferred over local models.

Furthermore, we mention that we do __not__ make use of the package default which applies binning to numerical features.
Binning is useful to achieve improved interpretability while it causes problems when sampling at the same time.
This issue is discussed in the next chapter.
We think that linear models are _per se_ interpretable by their coefficient.
However, in the context of LIME, the local explanation is considered interpretable by its feature contribution to the predicted target.

In order to improve interpretability when working with numerical features, we recommend multiplying the resulting local coefficients with the feature value to restore this kind of interpretability.


## The problem in a one-dimensional setting


How crucial the proper setting of the kernel width can be is illustrated by a very simple example.
We simulate data with one target and two features.
One feature is pure noise and the other one has a non-linear sinus-like effect on the target.
If we plot the influential feature on the x-axis and the target on the y-axis we can observe this pattern in figure \@ref(fig:fig2).

```{r, fig2, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Non-linear univariate relationship."}
knitr::include_graphics("images/04-09-02.png")
```

Now we fit a random forest on this problem which should be able to detect the non-linearity and incorporate it into its predictive surface.
In fact, we observe that the predictions of the random forest look very accurate in figure \@ref(fig:fig3)

```{r, fig3, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Random Forest Predictions."}
knitr::include_graphics("images/04-09-03.png")
```

LIME could now be used to explain this random forest locally.
"Good" local models would look very different w.r.t. the value of the feature.
We could describe the data locally well by piece-wise linear models.
This is depicted in figure \@ref(fig:fig4).

```{r, fig4, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Non-linear univariate relationship linearly interpolated."}
knitr::include_graphics("images/04-09-04.png")
```

LIME should be able to find these good local explanations given the right kernel size.
Let's select one instance whose true response is close to the predictive surface. 
We indicate this by the green point in figure 4.
This particular instance can be linearly described by linear regression with approximately intercept $60$ and slope $-4.5$.
If we set the kernel width to $0.08$, we actually fit this local model (on average).
This is indicated by the red line in figure 4.
However, if we increased the kernel width to $2$ the coefficients change to $-2.84$ (intercept) and $0.64$ (slope) (on average) which seems drastically distorted as observed by the yellow line in figure \@ref(fig:fig5).
The second line does not seem to fit a local linear model but rather a global one.

```{r, fig5, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Possible local models for univariately non-linear data."}
knitr::include_graphics("images/04-09-05.png")
```

More systematically, we review explanations resulting from altering the kernel size in figure \@ref(fig:fig6). 
We average over many different models to achieve more robust local models.
We do that because we observe some coefficient variations resulting from the (random) sampling.
In figure \@ref(fig:fig6) (upper panel) we see these averaged models for 7 different kernel sizes.
We observe that the larger we set the kernel size, the more we converge to a linear model that operates globally.
In fact, the largest three kernel sizes ($0.5$, $1$ and $2$) appear very global while $0.05$ and $0.1$ seem to fit good local models.
$0.25$ and $0.3$ are neither global nor very local.
This is very intuitive and complies with the idea of a weighted local regression.

Additionally, we analyse the same alteration of the kernel size for an observation where a good local approximation would be a linear model with a positive slope in the lower panel of figure \@ref(fig:fig6).
We observe a similar behaviour.

```{r, fig6, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local models for univariately non-linear data with different kernel sizes."}
knitr::include_graphics("images/04-09-06.png")
```

This behaviour is not necessarily a problem but only a property of the LIME.
However, it is problematic that the appropriate kernel size is not a priori clear.
Additionally, there is no straight forward way to determine a good kernel width for a given observation to be explained.
The only generic goodness-of-fit criterion of LIME, model fidelity, is endogenous w.r.t. the kernel size.
If we set the kernel size very small there will be many models with an extremely good local fit as local refers only to a single observation.
In our examples, it looks as if a very small kernel size should be preferred.
A small kernel width indeed grants local fit.
But what a small kernel width also strongly depends on the dimensionality and complexity of the problem.


## The problem in more complex settings


The previous setting was trivial for LIME.
We could visualise the predictive surface in the first place.
This means that interpretability was largely given in the first place.
We will study our problem in more complex settings to show that the problem persists.
We will do so by examining simulated and real data.


### Simulated data


We simulate data with multiple numeric features and a numeric target.
We assume the features to originate from a multivariate normal distribution where all features are moderately correlated.
Note that the choice of the normal distribution to be consistent with the assumptions within LIME.
We simulate three different data sets. 
In the first one, the true associations are linear (globally linear).
In the second one, the true associations are linear but only affect the target within a subinterval of the feature domain (locally linear).
This should examine LIME's ability to determine local feature importance.
In the third one, we exchange one of the linear associations from the first simulation with a non-linear one (globally non-linear).
For all three data sets, we expect the kernel width to have an impact on the resulting explainer.
However, for the global linear relationships, we expect the weakest dependency because the true local model and the true global model are identical.

We refrain from simulating more complex data sets as we strongly favour that the true marginal predictive surface is human interpretable.


#### Global Linear Relationships


We simulate data where the true predictive surface is a hyperplane.
Good machine learning models should be able to approximate the hyperplane.
This case is somewhat trivial as well for LIME.
The most suitable model for this data would be linear regression which is interpretable in the first place.
However, LIME can be easily tested in this controlled environment.
We know the true local coefficients as they equal to the global ones.
Thus, we can evaluate the goodness of the kernel width appropriately.

The simulated data looks as follows:
The feature space consists of three features ($x_1$, $x_2$, $x_3$).
All originate from a multivariate Gaussian distribution with mean $\mu$ and covariance $\Sigma$.
$\mu$ is set to be $5$ for all features and $\Sigma$ incorporates moderate correlation.
The true relationship of the features on the target $y$ is described by:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon $$
We set the true coefficients to be $\beta_1 = 4$, $\beta_2 = -3$, $\beta_3 = 5$.

We use linear regression (the true model) as a black-box model.
Using cross-validation, we confirm that the model has high predictive capacity.
Not surprisingly, the linear model describes the association very well. 

We choose random observations and compute the local LIME model for each one w.r.t. different kernel sizes.
In this case, we assume that the kernel size may be infinitely large as the global model should equal good local models.
However, if the kernel width is set too small we may fit too much noise.
Hence, in this case, we may find no good local models.

The figures below (all four panels of figure \@ref(fig:fig8)) indicate the local parameters for one of the selected observations for different kernel sizes which have been determined by LIME.
The three vertical lines indicate the true global coefficients.
Note that this is representative of all observations.

```{r fig8, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Coefficients for different kernel widhts."}
knitr::include_graphics("images/04-09-08.png")
```

We observe that too small kernel widths are not able to reproduce the global predictive surface at all.
However, moderately all kinds of kernel widths from moderate size to very large kernels fit very similar models which are all very close to the _true_ model.

These results allow concluding that for predictive surfaces corresponding to linear relationships, the kernel width is a non-critical parameter.
However, this case may be seen as trivial for most users of LIME.


#### Local Linear Relationships


For non-linear relationships, we have already seen that the kernel width is more crucial.
Thus, we aim to study the behaviour of the explanations w.r.t. the kernel size where the true associations are non-linear or _local_.

We may induce non-linearity by different means.
However, first of all it seems interesting to study how the kernel width affects LIME explanations in a very simple setting of non-linearity:
The features only affect the target locally linearly, as expressed by:

$$ y = \beta_0 + \beta_1 x_1 1_{x_1<c_1} + \beta_2 x_2 + \beta_3 x_3 + \epsilon + \gamma_0 1_{x_1>c_1} $$

where $x_1$ only affects $y$ within the given interval. 
$\gamma_0$ corrects the predictive surface by another intercept in order to avoid discontinuities.
This time, we fit a MARS model (@friedman1991multivariate) which can deal with this property of local features.
MARS is able to reproduce the data generating process perfectly and hence our first choice.
Using cross-validation, we in fact confirm that the model has high predictive capacity.
However, note that all of our results would be _qualitatively_ identical between MARS and random forest.
Given an appropriate kernel LIME should succeed in recovering the local predicitve surface.

We set $\beta_1 = 5$, $\beta_2 = -4$, $\beta_3 = 3$ and $c_1 = 5$.
This means that the slope of $\beta_1$ equals to $5$ until $x_1 = 5$ andto $0$ afterwards.
This results in an average slope of $2.5$.

We investigate _representative_ observations, i.e. one belonging to each _bin_ of the predictive surface in order to check if LIME recovers the local coefficients.

Representative now means that we should investigate observations with the following properties:

1. $x_1 < 5$ 

2. $x_1 > 5$ 

We think these observations are best explained in areas with reasonable margin to $c_1 = 5$.

Below in figure \@ref(fig:fig10), we depict the coefficient paths for four representative observations, two belonging to each bin.
The true local coefficients are displayed by solid vertical lines.

```{r, fig10, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for piece-wise local associations."}
knitr::include_graphics("images/04-09-10.png")
```

We can clearly see that in this case, we __cannot__ simply set an arbitrary kernel width.
The true local coefficient for $x_1$ is only approximated well within a narrow interval of the kernel width.
In our scenario, good kernel widths are between $0.25$ and $0.75$. (??)
As before, we observe that a too-small kernel width, however, produces non-meaningful coefficients.
In the limit, the true coefficient is not approximated, but rather the global (average) linear coefficient:
For $x_1$ a large kernel_width results in a linear model that averages the local slopes.
Additionally, we observe that for lower kernel widths, the local models are rather volatile.
More systematically, @alvarez2018robustness investigate this volatility and find that LIME is prone to finding instable explanations.

This motivates us to further investigate this volatility.
We display the mean and the confidence intervals of the coefficients of 100 different models for different kernel sizes in figure \@ref(fig:fig11) for $x_1$.
The black lines interpolate averaged coefficient estimates for different kernel sizes. 
The solid black line indicates the true local coefficient. 
The grey shaded area is the (capped) 95% confidence intervals.
For very low kernel widths we observe massive volatility.
The volatility decreases to an acceptable level only after $0.25$ for all covariates.

```{r, fig11,  eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for piece-wise local associations."}
knitr::include_graphics("images/04-09-11-1.png")
```

Note that we obtain the same picture for every covariate and other representative observations.
We observe that there is a trade-off between stable coefficients and locality (expressed by small kernel width).
In our analysis, it seems as if a good kernel size should tend to be as small as possible as long as the resulting explainer produces non-volatile coefficients.
Mathematically speaking, we aim the minimal kernel size so that it satisfies a volatility condition.


#### Global Non-Linearity


More generally, we aim to show that similar behaviour occurs if we induce more severe non-linearity.
As we strongly favour linear relationships, we further generalise the approache from the previous section and simulate data with the underlying data generating mechanism:

$$ y = \beta_0 + \beta_1 x_1 + \beta_{2,1} x_2 1_{x_2<c_1} + \beta_{2,2} x_2 1_{c_1 < x_2 < c_2} +  \beta_{2,3} x_2 1_{c_2 < x_2} + \beta_3 x_3 + \epsilon + \gamma_0 1_{c_1 < x_1 < c_2} + \gamma_0 1_{x_1 > c_2} $$

where the slope $\beta_2$ changes over the whole domain of $x_2$.
We set $\beta_1 = 5$, $\beta_{2,1} = -4$, $\beta_{2,2} = 3$, $\beta_{2,3} = -3$ $\beta_3 = 3$, $c_1 = 4$ and $c_2 = 6$.

We study three _representative_ observations complying with:

1. $x_2 < 4$

2. $4 < x_2 < 6$

3. $6 < x_2$

As before, we use a MARS model as our black box.
When explaining the black box with LIME we observe the same pattern as before in figures \@ref(fig:fig12) and \@ref(fig:fig13).
However, the interval if "good" solutions are -- naturally -- much smaller.
If we further increase the number of non-linear effects, this effect increases.
It seems as if the more complex the predictive surface, the harder it is for LIME to even find a good local model.

We also find for globally non-linear associations that we prefer a small kernel width which however yields stable coefficients in order to achieve a (second best) optimal local model.
This observation is very crucial with regard to real-world data.
As soon as explanations are stable, we may easily end up with explainers that are biased towards the global surrogate.

```{r, fig12, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for non-linear associations"}
knitr::include_graphics("images/04-09-12.png")
```

```{r, fig13, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients and cofidence bands for different kernel widths for non-linear associations (for x2)."}
knitr::include_graphics("images/04-09-13.png")
```

Having investigated simulated data where we knew the ground truth gave us a good feeling on how the kernel size affects the resulting explainer model.
The neighbourhood problem can be described briefly by the following.
A (too) small kernel width creates instable coefficients whilst a too large kernel width fits a global surrogate model.
An optimal kernel size should balance these effects.
We may formulate the problem as a mininmisation problem w.r.t. the kernel size subjected to the constraint that coefficients need to be stable.


### Real data


Leaving the controlled environment we may face more challenges than we used to.
Many, however, are related to the sampling of LIME and thus will be neglected in this chapter.

1. High-dimensional data is also for the kernel width an issue to consider.
LIME computes dissimilarities of observations to each other.
It is well-known that dissimilarities get increasingly less meaningful as the feature space expands.
This is one consequence of the curse of dimensionality.

2. Computing some dissimilarities (e.g. Manhattan or euclidean) also comes with the problem that the cardinality of the features mainly steers this measure.
Thus, LIME should always apply scaling.

3. When working with real data sets with many features, we typically want a sparse explanation.
In order to achieve this, we should let LIME do the feature selection.

Note that the latter two are featured in the Python and R implementations.

Within this section, we study whether we find the same behaviour as we did for simulated data in the previous sections for a real data set.
We will work with the well-known Washington D.C. bicycle rental data set.
This dataset contains daily bicycle hire counts of a Washington D.C. based rental company. The data has been made openly available by the company itself (Capital-Bikeshare). 
@fanaee2014event added supplementary information on the weather data and season associated with each day.
For details on the data set please refer to @molnar2019. (https://christophm.github.io/interpretable-ml-book/bike-data.html).
We select this data set because it is well-known in the machine learning community and this regression problem is accessible to most people.
Furthermore, it has a reasonable feature space making it not highly prone to the curse of dimensionality of the distance measures.
Note that we only use a subset of all possible features as some are somewhat colinear.

Using this data we aim to use a random forest to predict the number of daily bicycle hires. 
We tune the forest using cross-validation.
We use LIME to explain the black box.
The model performs (on average) reasonably well with a root mean squared error of 1233 on the held-out data while the mean of the bicycle rental count is 4284. 

When working with LIME in practice, we want to obtain stable explanations. 
An explanation is stable if the surrogate model does not change much when altering the randomly drawn samples.
We evaluate this property with the aid of modified stability paths (@meinshausen2010stability).
Stability paths are used for sparse (regularised) models and indicate how likely each covariate is part of the model.
Normally, they analyse the association of the regularisation strength and these inclusion probabilities.
In our context, we rather aim to study how likely a covariate is part of the model for a given regularisation (number of features) over a grid of kernel widths.
Stability paths are much easier to use when there are many features to be analysed.

Over a grid of kernel widths (from almost 0 to 20), we compute multiple sparse explanations for the same kernel width.
Sparse means that we limit our explainer to only the three most influential local features.
We count how frequently each covariate has been part of the explanation model for all explanations we computed for the same kernel width.
We divide by the total number of iterations and achieve estimates for the sampling probability for a given observation, a given number of features and a given kernel width.
We search the full grid of kernel widths and can repeat this procedure for different observations.

Our pseudo stability paths are stable in areas where we have extreme probabilities, i.e. either probabilities close to 1 or close to 0.
Furthermore, they should not change extremely when the kernel width slightly changes.

In figure \@ref(fig:fig14), we display the stability paths for different observations for our random forest.

```{r fig14, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Stability paths for the bycicle data set explaining a random forest"}
knitr::include_graphics("images/04-09-14.png")
```

We observe that stability paths converge to a set of covariates if we set the kernel width large.
These are the global features.
There is one interesting observation about this.
Different observations sometimes converge to different global surrogate models.
The covariates humidity and temperature are always selected.
Then, either the windspeed or the season is selected as global feature.
We believe that this is due to the fact that both covariates are similarly strong on the global scope.

Furthermore, we observe that for small values of the kernel width we have - like in our simulation - high variation.
Here, this variation is expressed with intersecting paths where most covariates are equally likely to be sampled.

For some observations, there seems to be a narrow range where there are stable and local explanation.
For instance, consider ... and...
We may conclude that in fact for observations 1 and 2 a stable and local explanation would involve the season, the temperature and the weather situation.
However, for observation 2, a possible (less) stable explanation would also involve the season, the temperature and the indicator for a working day.

So even though we may find meaningful explanations from case to case, there is too much clutter to be finally sure about the explanations' goodness.
Furthermore, "local" explanations still seem quite global as they occur for many different observations.
The only truly stable explanations remain essentially global explanations.
It seems as if the predictive surface is too complex to facilitate local and stable surrogate models properly.

We observe both effects that are described in the literature for our real data example: 
instability (@alvarez2018robustness) for small kernel widths and global surrogates (@laugel2018defining) for larger ones.
For simulated data, we could observe these effects as well.
At the same time, we were able to identify local and stable explanations in this controlled environment.
For real data, however, it is hard to locate the area which we identified for simulated data where we find a stable __and__ local model.


## Discussion and outlook


LIME is capable of finding local models.
We show this with simulated data.
The specification of a proper kernel width is crucial in order to achieve this.
A proper locality is expressed by the minimal kernel width producing stable coefficients.
However, we see that especially the sampling procedure makes it - in practise - difficult to find these models.
In fact, we were unable to detect explanations that were both, stable and local, for our real data application -- at least with certainty.
We largely observe the pattern described by @laugel2018defining who claim that LIME explanations are strongly biased towards global features.
At the same time, our study agrees with @alvarez2018robustness who find that local explanations are highly instable.
We confirm these findings using the bicycle rental data set. 
Additionally, also for simulated data, it becomes harder to detect a good locality if the predictive surface becomes too complex as the interval for suitable localities becomes narrower.

Note that we, in fact, found similar behaviour for many different data sets.
For the practitioner using LIME (for tabular data) this means that LIME should be used with great care.
Furthermore, we suggest analysing the resulting explanations for their stability.

We propose that LIME should be altered in the way proposed by @laugel2018defining to LIME-K.
Local sampling should replace global sampling to better control for the locality.

Even though having said this, we think that LIME is one of the most promising contributions to the Interpretable Machine Learning community.
The problems described in this chapter are mainly associated with tabular data.
Domains where LIME has been applied successfully include image data and text data.
Within these domains, LIME works differently from tabular data.
For example, LIME's sampling for text data is very local, only creating perturbations based on the instance to be explained.


## Note to the reader


### Packages used


For our analysis we use R (@R-base).
For all black box models we used the mlr package (@R-mlr) and the lime package (@R-lime) for the LIME explanations.
All plots are created using @R-ggplot2.


### How we used the lime R package and why


We strongly recommend to not bin numerical features.
The next chapter will outline in detail why this is not a good idea.
However, in the first place there was no reason for the binning except enhanced interpretability.
We suggest, though, that the same interpretability can be obtained by the absolute contribution of the feature to the prediction.
This means instead of the local coefficient, LIME should rather print the local coefficient times the feature value within its explanation.

While we think Gower distance is an interesting approach to deal with mixed data, we explicitely promote not to use it.
In the current (July 2019) R implementation, when working with Gower distance there is no kernel applied.
Explanations do not correspond to altering the kernel width.
As we have seen, a proper kernel width may look very different depending on the associated problem.
So it is highly unlikely that a one-size-fits-all implicit kernel width always results in the proper kernel width.
In figure \@ref(fig:fig15) we analyse this statement by comparing the gower distance local coefficient to the true coefficient and the local estimates of the non-linear data simulation.

```{r fig15, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data (non-linear): Gower distance vs. Euclidean distance"}
knitr::include_graphics("images/04-09-15.png")
```

Even though we think that Gower distance may result in some cases in good local models, its (currently) lacking flexibility most likely causes non-local surrogates.

Usually, LASSO is the preferred option for variable selection as it is less deterministic as, let's say, step-wise forward selection.
However, we do not use LASSO but step-wise forward selection because the current implementation of LASSO has shortcomings and does not deliver results suitable for our analysis.
