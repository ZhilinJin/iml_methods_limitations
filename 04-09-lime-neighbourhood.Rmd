# LIME and Neighbourhood

*Author: Philipp Kopper*

How much neighbourhood may be an issue can be illustrated in a setting very different to LIME:
Descriptive statistics or in particular kernel density estimations.
The figure below illustrates kernel densities from a standard normal distribution.
One can easily see that the second panel seems to be appropriate while the first one is too granular and the third one does not feature any information.
The proper definition of the neighbourhood is in this case very crucial.
However, a priori - with no prior information - this definition is arbitrary.
We can only judge on the proper definition of the neighbourhood from our experience and our expectations.
This may work in low dimensional problems and descriptive statistics.
However, machine learning models operate in multivariate space and mostly tackle complex associations.
Thus, it seems much harder to argue on the proper neighbourhood definition when working with LIME.

This chapter reviews the neighbourhood issue w.r.t. the LIME algorithm critically.
First of all, it describes the neighbourhood defintion absractly (section 1).
Then, it reviews possible implementations with special emphasis on the implementation in Python and R (section 2).
Section 3 discusses inherent problems and potential issues of the current implementations.
In section 4 we examine the coefficient stability of LIME explanations w.r.t to altering the neighbourhood definition within an experiment in R.
We use both, simulated and real data.
We make use of the stability selection algorithm which is explained in section 4.1.
Finally, section 5 concludes reviewing the take-aways of this chapter and proposing an improved algorithm w.r.t. the neighbourhood issue.

## The Neighbourhood in LIME

When obtaining explanations with LIME the neighbourhood of an instance is determined when fitting the model by applying weights to instances w.r.t. proximity to the instance of interest.
However, it is important to note that this step is already arbitrary.
@craven1996 show that increasing the density of observations around the instance of interest is very helpful to achieve model fidelity.
This could be obtained in many other ways than weighting observations as in LIME.
One possible alternative might be to combine steps 2 (sampling) and 4 (weighting) of the LIME algorithm.
This way we would increase the density around the instance already by proper sampling. 
In fact, @laugel2018defining claim that this way should be preferred over the way LIME samples.
In this chapter, however, we focus on the explicit implementation in LIME and analyse how the weighting strategy _ceteris paribus_ affects surrogate model stability.
This can be seen as a motivation for @laugel2018defining.

In LIME the weighting of instances is performed using a kernel function over the distances of instances to the instance of interest.
This leaves us two _arbitrary_ (in fact they may not be that arbitrary) choices:
the distance and the kernel function.
Typical distance functions applicable to statistical data analysis are based on the L0, L1 and L2 norms.
For numerical features one tends to use either manhattan distance (L1) or euclidean distance (L2).
For categorical features one would classically apply hamming distance (L0).
Mixed data (data with both categorical and numerical features) usually one combines distances for numerical and categorical features.
So does Gower's distance @Gower 
$$ d_G $$
or a bit more general the distance proposed by @Huang1997kproto

$$ d_H $$
with $\lamda$ steering the importance of categorical features relative to numerical ones.
However, it is important to note that despite these mesasures it may be challenging to properly determine distances for mixed data.
For image and text data @ribeiro2016should recommend using...
By default...

For the kernel function itself there are two hyperparameters to be set.
First of all the type of the kernel.
Second, the kernel width.
By default...

How crucial the kernel width is can be visualised by the graph below.
..
We can show that for the underlying data for the graph a kernel width of X results in the surrogate model featuring a coefficient of X (on average) which seems accurate within the locality. 
However, if we increased the kernel width to XX the coefficient changes to XX (on average) which seems drastically distorted.


### WO?
Another problem will certainly be high-dimensional data. 
In high dimensions distance measures increasingly become less meaningful (curse of dimensionality).
Thus, the higher the dimension the less we can enforce locality.
### ENDE WO?

## Experimental study 

As the choice of the distance measure seems least arbitrary and the choice of the kernel function is not expected to have crucial impact on the neighbourhood definition, we focus on the kernel width in our experimental study.
We evaluate the explanations of LIME with respect to altering the kernel width _ceteris paribus_. 
We do this for both, simulated and real world data.
For simulated data we focus on LIME's capability of finding local decision boundaries.
For real data we emphasise coefficient stability of LIME explainers.

We simulate for different rather simple data sets.
In all examples we will investigate regression tasks.
The first one exhibits solely linear relationships of the feature with the target.
All features are moderatley correlated.
The second one will additionally contain a non-linear effect.
The third one features interaction terms.
For all of these data sets we will evaluate if LIME can find a good local model (measured by local fidelity) and we will illustrate how strongly the kernel size is responsible for this to happen.
We will illustrate in this case how a _good_ kernel size can be determined and that it is important to set the kernel size locally.

The real data set is... 
EXPLANATIONS WHAT IT IS
First of all, we will show that the same problems as for simulated data persist for real data.
When LIME is used in practise on real data, we aim that it produces consistent, or in other words stable, results.
This means that if the input slighlty changes, we wish the explanation not to drastically change as well.
We examine the stability of the explanations by coefficient and so-called stability paths.
Stability paths are explained in detail below.
We study how drastically explanations differ at different kernel sizes if we explain the nearest neighbours of the instance to be explained are used instead.

## Simulated data

We simulate the first data set with the following R code.
```{r simulation_1}

```












