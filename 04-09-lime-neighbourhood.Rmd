---
output:
  html_document: default
  pdf_document: default
---
# LIME and Neighbourhood {#id1}

*Author: Philipp Kopper*

This section will discuss the effect of the neighbourhood on LIME's explanations.
This is very critical for tabular data only.
Hence, we will limit ourselves to the analysis of tabular data for the remainder of this chapter.

As described in the previous chapter, LIME aims to create local surrogate models -- one for each observation to be explained.
These local models operate in the proximity or _neighbourhood_ of the instance to be explained.
They are fit based on weights which indicate their proximity to the observation to be explained.
The weights are typically determined using kernels that transform the proximity measure.

The proper parametrisation of the kernel is obviously important.
However, this is true for any approach that uses kernels.
Such as kernel density estimations.
Figure \@ref(fig:fig1) illustrates kernel densities from a standard normal distribution.
We applied different kernel widths for the curve estimation.

```{r, fig1, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "The appropriate kernel width for kernel density estimations."}
knitr::include_graphics("images/04-09-01.png")
```

One can easily see that the first panel seems to be appropriate while the second one is too granular.
The proper definition of the neighbourhood is very crucial in this case.
However, with no prior information, this definition is arbitrary.
We can only judge on the proper definition of the neighbourhood from our experience and our expectations.
This may work in low dimensional problems and descriptive statistics.
However, machine learning models operate in multivariate space and mostly tackle complex associations.
Thus, it seems much harder to argue on the proper neighbourhood definition when working with LIME.

This chapter reviews this neighbourhood issue w.r.t. the LIME algorithm critically.
The objective of this chapter is more to outline this particular issue and not to suggest solutions for it.
First of all, it describes the neighbourhood definition abstractly in greater detail (section \@ref(id2)). 
Then, it illustrates how problematic the neighbourhood definition is in a simple one-dimensional example in section \@ref(id3). 
Furthermore, we study the effect of altering the kernel size more systematically in more complex contexts in the next section (\@ref(id4)). 
This section deals with both simulated (\@ref(id41)) and real (\@ref(id42)) data.
The first subsection of the simulation (\@ref(id411)) investigates multivariate globally linear relationships.
The second one (\@ref(id412)) researches local coefficients.
The third one (\@ref(id413)) studies non-linear effects.
Afterwards in section \@ref(id5), we discuss the results and contextualise them with existing literature.
After concluding, we explain how LIME was used and why in section \@ref(id6).


## The Neighbourhood in LIME in more detail {#id2}


When obtaining explanations with LIME the neighbourhood of an instance is determined when fitting the model by applying weights to instances w.r.t. proximity to the instance of interest.
However, there is no natural law stating that local models have to be found this way.
@craven1996 show that increasing the density of observations around the instance of interest is very helpful to achieve model fidelity.
This could be obtained in many more ways than weighting observations as done in LIME where global sampling takes place.
After sampling the samples are weighted w.r.t. their proximity to the observation to be explained.
One possible alternative might be to combine steps 2 (sampling) and 4 (weighting) of the LIME algorithm (see cross-ref prevoius section) to a local sampling.
This way we would increase the density around the instance already by proper sampling. 
In fact, @laugel2018defining claim that this way should be preferred over the way LIME samples.
In this chapter, however, we focus on the explicit implementation in LIME and analyse how the weighting strategy _ceteris paribus_ affects surrogate model stability.

When working with LIME, the weighting of instances is performed using a kernel function over the distances of instances to the instance of interest.
This leaves us _arbitrary_ (in fact they may not be _that_ arbitrary) choices on two parameters:
the distance and the kernel function.
Typical distance functions applicable to statistical data analysis are based on the L0, L1 and L2 norms.
For numerical features, one tends to use either manhattan distance (L1) or euclidean distance (L2).
For categorical features one would classically apply hamming distance (L0).
For mixed data (data with both categorical and numerical features), one usually combines distances for numerical and categorical features.
So does Gower's distance @gower1971general or the distance proposed by @huang1998kproto:

$$ d_H(x_i, x_j) = d_{euc}(x_i, x_j) + \lambda d_{ham}(x_i, x_j) $$

with $d_{euc}$ referring to the euclidean distance and $d_{ham}$ to the hamming distance.
$d_{euc}$ is only computed for numerical and $d_{ham}$ only for categorical ones.
$\lambda$ steers the importance of categorical features relative to numerical ones.
@huang1998kproto recommends setting $\lambda$ equal to the average standard deviation of the numerical features.
For scaled numerical features (standard deviation is one).
For this case, this means that $d_H = d_{euc}$ if categorical features are one-hot-encoded.
It is important to note that despite these measures it may be challenging to properly determine distances for mixed data. 
@ribeiro2016should recommend using cosine distance for text and
Euclidean distance for images.

For the kernel function itself, there are two hyperparameters to be set.
First of all the type of kernel type.
Second, the kernel width.
By default, the R implementation implements an exponential kernel where the kernel width equals the square root of the number of features.

As the choice of the distance measure seems least arbitrary and the choice of the kernel function is not expected to have the most crucial impact on the neighbourhood definition, we focus on the kernel width in our experimental study.


## The problem in a one-dimensional setting {#id3}


How crucial the proper setting of the kernel width can be is illustrated by a very simple example.
We simulate data with one target and two features.
One feature is pure noise and the other one has a non-linear sinus-like effect on the target.
If we plot the influential feature on the x-axis and the target on the y-axis we can observe this pattern in figure \@ref(fig:fig2).

```{r, fig2, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Non-linear univariate relationship."}
knitr::include_graphics("images/04-09-02.png")
```

Now we fit a random forest on this problem which should be able to detect the non-linearity and incorporate it into its predictive surface.
In fact, we observe that the predictions of the random forest look very accurate in figure \@ref(fig:fig3)

```{r, fig3, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Random Forest Predictions."}
knitr::include_graphics("images/04-09-03.png")
```

LIME could now be used to explain this random forest locally.
"Good" local models would look very different w.r.t. the value of the feature.
We could describe the data locally well by piece-wise linear models.
This is depicted in figure \@ref(fig:fig4).

```{r, fig4, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Non-linear univariate relationship linearly interpolated."}
knitr::include_graphics("images/04-09-04.png")
```

LIME should be able to find these _good_ local explanations given the right kernel size.
Let's select one instance which we want an explaination for.
We illustrate this instance by the green point in figure \@ref(fig:fig5).
This particular instance can be linearly described by linear regression with approximately intercept $60$ and slope $-4.5$.
If we set the kernel width to $0.08$, we actually fit this local model (on average).
This is indicated by the red line in figure \@ref(fig:fig5).
However, if we increased the kernel width to $2$ the coefficients change to $-2.84$ (intercept) and $0.64$ (slope) (on average) which seems drastically distorted as observed by the yellow line in figure \@ref(fig:fig5).
The yellow line does not seem to fit a local linear model but rather a global one.

```{r, fig5, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Possible local models for univariately non-linear data."}
knitr::include_graphics("images/04-09-05.png")
```

More systematically, we review explanations resulting from altering the kernel size in figure \@ref(fig:fig6). 
We average over many different models to achieve more robust local models.
We do that because we observe some coefficient variations resulting from the (random) sampling.
In figure \@ref(fig:fig6) (upper panel) we see these averaged models for 7 different kernel sizes.
We observe that the larger we set the kernel size, the more we converge to a linear model that operates globally.
In fact, the largest three kernel sizes ($0.5$, $1$ and $2$) appear very global while $0.05$ and $0.1$ seem to fit good local models.
$0.25$ and $0.3$ are neither global nor very local.
This is very intuitive and complies with the idea of a weighted local regression.

Additionally, we analyse the same alteration of the kernel size for an observation where a good local approximation would be a linear model with a positive slope in the lower panel of figure \@ref(fig:fig6).
We observe a similar behaviour.

```{r, fig6, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local models for univariately non-linear data with different kernel sizes."}
knitr::include_graphics("images/04-09-06.png")
```

This behaviour is not necessarily a problem but only a property of the LIME.
However, it can be problematic that the appropriate kernel size is not a priori clear.
Additionally, there is no straight forward way to determine a good kernel width for a given observation to be explained.
The only generic goodness-of-fit criterion of LIME, model fidelity, is endogenous w.r.t. the kernel size.
If we set the kernel size extremely small there will be many models with an extremely good local fit as local refers only to a single observation.
In our examples, it looks as if a very small kernel size should be preferred.
A small kernel width indeed grants local fit.
But what a small kernel width is also strongly depends on the dimensionality and complexity of the problem.


## The problem in more complex settings {#id4}


The previous setting was trivial for LIME.
The problem was univariate and we could visualise the predictive surface in the first place.
This means that interpretability was largely given.
We will study our problem in more complex settings to show that the problem persists.
We will do so by examining simulated and real data.


### Simulated data {#id41}


We simulate data with multiple numeric features and a numeric target.
We assume the features to originate from a multivariate normal distribution where all features are moderately correlated.
Note that the choice of the normal distribution to be consistent with the assumptions within LIME.
We simulate three different data sets. 
In the first one, the true associations are linear (globally linear).
In the second one, the true associations are linear but only affect the target within a subinterval of the feature domain (locally linear).
This should examine LIME's ability to assess local features.
In the third one, we examine globally non-linear associations.
For all three data sets, we expect the kernel width to have an impact on the resulting explainer.
However, for the global linear relationships, we expect the weakest dependency because the true local model and the true global model are identical.


#### Global Linear Relationships {#id411}


We simulate data where the true predictive surface is a hyperplane.
Good machine learning models should be able to approximate the hyperplane.
This case is -- again -- somewhat trivial for LIME.
The most suitable model for this data would be linear regression which is interpretable in the first place.
Thus, LIME can be easily tested in this controlled environment.
We know the true local coefficients as they equal to the global ones.
We can evaluate the goodness of the kernel width appropriately.

The simulated data looks as follows:
The feature space consists of three features ($x_1$, $x_2$, $x_3$).
All originate from a multivariate Gaussian distribution with mean $\mu$ and covariance $\Sigma$.
$\mu$ is set to be $5$ for all features and $\Sigma$ incorporates moderate correlation.
The true relationship of the features on the target $y$ is described by:

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon $$
We set the true coefficients to be $\beta_1 = 4$, $\beta_2 = -3$, $\beta_3 = 5$.

We use linear regression (the true model) as a black-box model.
Using cross-validation, we confirm that the model has high predictive capacity.
Not surprisingly, the linear model describes the association very well. 

We choose random observations and compute the local LIME model for each one w.r.t. different kernel sizes.
In this case, we assume that the kernel size may be infinitely large as the global model should equal good local models.
However, if the kernel width is set too small we may fit too much noise.
Hence, in this case, we may find no good local models.

The figures below (all four panels of figure \@ref(fig:fig8)) indicate the local parameters for one of the selected observations for different kernel sizes which have been determined by LIME.
The three vertical lines indicate the true global coefficients.
This behaviour is representative of all observations.

```{r fig8, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Coefficients for different kernel widhts."}
knitr::include_graphics("images/04-09-08.png")
```

We observe that too small kernel widths are not able to reproduce the global predictive surface at all.
However, from here on all kinds of kernel widths from small size to very large kernels fit very similar models which are all very close to the _true_ model.

These results allow concluding that for explaining linear models the kernel width is a non-critical parameter.
However, this case may be seen as trivial for most users of LIME.


#### Local Linear Relationships {#id412}


For non-linear relationships, we have already seen that the kernel width is more crucial.
Thus, we aim to study the behaviour of the explanations w.r.t. the kernel size where the true associations are non-linear or _local_.

We may induce non-linearity by different means.
However, first of all it seems interesting to study how the kernel width affects LIME explanations in a very simple setting of non-linearity:
The features only affect the target locally linearly, as expressed by:

$$ y = \beta_0 + \beta_1 x_1 1_{x_1<c_1} + \beta_2 x_2 + \beta_3 x_3 + \epsilon + \gamma_0 1_{x_1>c_1} + \epsilon_i$$

where $x_1$ only affects $y$ within the given interval. 
$\gamma_0$ corrects the predictive surface by another intercept in order to avoid discontinuities.
This time, we fit a MARS model (@friedman1991multivariate) which can deal with this property of local features.
MARS is able to reproduce the data generating process perfectly and hence our first choice.
Using cross-validation, we in fact confirm that the model has high predictive capacity.
However, note that all of our results would be _qualitatively_ (MARS turns out to feature clearer results.) identical between MARS and random forest.
Given an appropriate kernel, LIME should succeed in recovering the local predicitve surface.

We set $\beta_1 = 5$, $\beta_2 = -4$, $\beta_3 = 3$ and $c_1 = 5$.
This means that the slope of $\beta_1$ equals to $5$ until $x_1 = 5$ and to $0$ afterwards.
This results in an average slope of $2.5$.

We investigate _representative_ observations, i.e. one belonging to each _bin_ of the predictive surface in order to check if LIME recovers all local coefficients.

Representative means that we should investigate observations with the following properties:

1. $x_1 < 5$ 

2. $x_1 > 5$ 

We think these observations are best explained in areas with reasonable margin to $x_1 = 5$.

Below in figure \@ref(fig:fig10), we depict the coefficient paths for four representative observations, two belonging to each bin (upper panels $x_1 < 5$, lower panels $x_1 > 5$).
The true local coefficients are displayed by solid vertical lines.

```{r, fig10, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for piece-wise local associations."}
knitr::include_graphics("images/04-09-10.png")
```

We can clearly see that in this case, we __cannot__ simply set an arbitrary kernel width.
The true local coefficient for $x_1$ is only approximated well within an interval of the kernel width.
In our scenario, good kernel widths are between $0.5$ and $2$.
As before, we observe that a too-small kernel width, however, produces non-meaningful coefficients.
In the limit, the true coefficient is not approximated, but rather the global (average) linear coefficient:
For $x_1$ a large kernel width results in a linear model that averages the local slopes.
This can also be interpreted as global surrogate.
Additionally, we observe that for lower kernel widths, the local models are rather volatile.
More systematically, @alvarez2018robustness investigate this volatility and find that LIME is prone to finding instable explanations.

This motivates us to further investigate the volatility.
We display the mean and the confidence intervals of the coefficients of 100 different models for different kernel sizes in figure \@ref(fig:fig11) for $x_1$.
The black lines interpolate averaged coefficient estimates for different kernel sizes. 
The solid black line indicates the true local coefficient. 
The grey shaded area is the (capped) 95% confidence intervals.
For very low kernel widths we observe massive volatility.
The volatility decreases to an acceptable level only after $0.25$ for all covariates.

```{r, fig11,  eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for piece-wise local associations."}
knitr::include_graphics("images/04-09-11-1.png")
```

Note that we obtain the same picture for every covariate and other representative observations.
We observe that there is a trade-off between stable coefficients and locality (expressed by small kernel width).
Our analysis suggests the following.
Large kernel sizes result in explanations biased towards a global surrogate.
At the same time, the kernel width must result in stable coefficients.
This means, we cannot set it infinitissimately small.
The resulting trade-off suggests to choose the minimal kernel size with stable coefficients.
Mathematically speaking, we aim minimal kernel size which still satisfies a volatility condition.


#### Global Non-Linearity {#id413}


More generally, we aim to show that LIME succeeds in finding local models if we induce more severe non-linearity.
We further generalise the approach from the previous section and simulate data with the underlying data generating mechanism:

$$ y = \beta_0 + \beta_1 x_1 + \beta_{2,1} x_2 1_{x_2<c_1} + \beta_{2,2} x_2 1_{c_1 < x_2 < c_2} +  \beta_{2,3} x_2 1_{c_2 < x_2} + \beta_3 x_3 + \epsilon + \gamma_0 1_{c_1 < x_1 < c_2} + \gamma_0 1_{x_1 > c_2} $$

where the slope $\beta_2$ is piece-wise linear and changes over the whole domain of $x_2$.
We set $\beta_1 = 5$, $\beta_{2,1} = -4$, $\beta_{2,2} = 3$, $\beta_{2,3} = -3$ $\beta_3 = 3$, $c_1 = 4$ and $c_2 = 6$.

We study three _representative_ observations complying with:

1. $x_2 < 4$

2. $4 < x_2 < 6$

3. $6 < x_2$

As before, we use a MARS model as our black box.
When explaining the black box with LIME we observe the same pattern as before.
Figures \@ref(fig:fig12) and \@ref(fig:fig13) look very similiar to the corresponding figures of the previous section,
However, the intervals of "good" solutions are -- naturally -- much smaller.
The more complex the true associations become, the more we observe this trend of decreasing solution intervals.
It seems as if the more complex the predictive surface, the harder it is for LIME to even find a good local model.

For globally non-linear associations, we also find that we prefer a small kernel which also produces stable coefficients.

```{r, fig12, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients for different kernel widths for non-linear associations"}
knitr::include_graphics("images/04-09-12.png")
```

```{r, fig13, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data: Local coefficients and cofidence bands for different kernel widths for non-linear associations (for x2)."}
knitr::include_graphics("images/04-09-13.png")
```

Having investigated simulated data where we knew the ground truth gave us a good feeling on how the kernel size affects the resulting explainer model.
The neighbourhood problem can be described briefly by the following.
A (too) small kernel width creates instable coefficients whilst a too large kernel width fits a global surrogate model.
An optimal kernel size should balance these effects.
We may formulate the problem as a mininmisation problem w.r.t. the kernel size.
However, the minimisation needs to consider the constraint that coefficients need to be stable.


### Real data {#id42}


Leaving the controlled environment we may face more challenges than we used to.
Many, however, are related to the sampling of LIME and thus will be neglected in this chapter.

1. High-dimensional data may be an issue for the computation of the kernel width.
LIME computes dissimilarities.
It is well-known that dissimilarities get increasingly less meaningful as the feature space expands.
This is one consequence of the curse of dimensionality.

2. Computing some dissimilarities (e.g. Manhattan or euclidean) also comes with the problem that the cardinality of the features mainly steers this measure.
Thus, LIME should always apply scaling.

3. When working with real data sets with many features, we typically want a sparse explanation.
In order to achieve this, we should let LIME do the feature selection.

Luckily, the latter two are featured in the Python and R implementations.

Within this section, we study whether we can confirm our simulated data findings for real world data.
We will work with the well-known Washington D.C. bicycle rental data set.
This dataset contains daily bicycle hire counts of a Washington D.C. based rental company. The data has been made openly available by the company itself (Capital-Bikeshare). 
@fanaee2014event added supplementary information on the weather data and season associated with each day.
For details on the data set please refer to @molnar2019. (https://christophm.github.io/interpretable-ml-book/bike-data.html).
We select this data set because it is well-known in the machine learning community and this regression problem is easily accessible to most people.
Furthermore, it has a reasonable feature space making it not highly prone to the curse of dimensionality of the distance measures.
We only make use of a subset of all possible features as some are somewhat colinear.

Using this data we aim to use a random forest to predict the number of daily bicycle hires. 
We tune the forest using cross-validation.
The model has a cross-validated root mean squared error of 1233 while the mean of the bicycle rental count is 4284.
We use LIME to explain the black box.

When working with LIME in practice, we want to obtain stable explanations. 
An explanation is stable if the surrogate model does not change much when altering the randomly drawn samples.
We evaluate this property with the aid of modified stability paths (@meinshausen2010stability).
Stability paths are used for sparse (regularised) models and indicate how likely each covariate is part of the model.
Normally, they analyse the association of the regularisation strength and inclusion probabilities of features.
On the x-axis one depicts the regularisation strength and on the y-axis the inclusion probabilities (for all covariates). 
The probabilities for different regularisations are grouped by feature.

However, we rather aim to study how likely a covariate is part of the (sparse) model over a grid of kernel widths.
Stability paths are much easier to use when there are many features to be analysed.

Over a grid of kernel widths (from almost 0 to 20), we compute multiple sparse explanations for the same kernel width.
Sparse means that we limit our explainer to only the three most influential local features.
We count how frequently each covariate has been part of the explanation model (out of all iterations).
We divide by the total number of iterations and achieve estimates for the sampling probability for a given observation, a given number of features and a given kernel width.
We search the full grid of kernel widths.
We can repeat this procedure for another observation.

Our _pseudo_ stability paths are stable in areas where we have extreme probabilities, i.e. either probabilities close to 1 or close to 0.
Furthermore, they should not change extremely when the kernel width slightly changes.

In figure \@ref(fig:fig14), we display the stability paths for different selected observations for our random forest.

```{r fig14, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Stability paths for the bycicle data set explaining a random forest"}
knitr::include_graphics("images/04-09-14.png")
```

We observe that stability paths converge to a set of covariates if we set the kernel width large.
These are the global features.
There is one interesting observation about this.
Different observations sometimes converge to different global surrogate models.
The covariates humidity and temperature are always selected.
Then, either the windspeed (all observations except number 3) or the season (e.g. observation 3) is selected as global feature.
We believe that this is due to the fact that both covariates are similarly strong on the global scope.

Furthermore, we observe that for small values of the kernel width, we have -- like in our simulation -- high variation.
Here, this variation is expressed by intersecting paths where most covariates are (almost) equally likely to be sampled.

For some observations, there seems to be a narrow range where there are stable and local explanation.
For instance, consider observation 1 and 8 where the local models seem quite clear.
For observation 1 between kernel widths of $0.5$ and $1$, it seems as if the temperature, the humidity and the weather situation are most influential.
For observation 8, the selected local features are temperature, humidity and season.
For other observations, such as observations 3 and 4, we may argue that there are local and stable local explanations, too.
These are, however, by far less convincing than the previous ones.
Additionally, we are struggling to identify stable local models for many observations, like observation 2 and 6.
For those observations, there is only instability for small kernel widths which transforms immiediately to the global surrogate once stabilised.
The reasons for this variation behaviour can be manifold.
However, not knowing the ground truth, it is hard to evaluate what is going on here in particular.

So even though we may find meaningful explanations from case to case, there is too much clutter to be finally sure about the explanations' goodness.
Furthermore, "local" explanations still seem quite global as they seem quite similar for many different observations.
Considering our explanations, the sparse models were highly correlated consisting of similar features for different observations.
The only truly stable explanations remain essentially global ones with large kernel width.
It seems as if the predictive surface is too complex to facilitate local and stable surrogate models properly.

We observe both effects being described in literature for our real data example: 
instability (@alvarez2018robustness) for small kernel widths and global surrogates (@laugel2018defining) for larger ones.
For simulated data, we could observe these effects as well.
At the same time, we were able to identify local and stable explanations in this controlled environment.
For real data, however, it is hard to locate the area which we identified for simulated data where we find a stable __and__ local model.


## Discussion and outlook {#id5}


LIME is capable of finding local models.
We show this with simulated data.
The specification of a proper kernel width is crucial in order to achieve this.
A proper locality is expressed by the minimal kernel width producing stable coefficients.
However, we see that it is difficult to find these models in practise.
In fact, we were unable to detect explanations that were both, stable and local, for our real data application -- at least with certainty.
We largely observe the pattern described by @laugel2018defining who claim that LIME explanations are strongly biased towards global features.
At the same time, our study agrees with @alvarez2018robustness who find that local explanations are highly instable.
We confirm these findings using the bicycle rental data set. 
Additionally, also for simulated data, it becomes harder to detect a good locality if the predictive surface becomes more complex.

Note that we, in fact, found similar behaviour for many different data sets.
For the practitioner using LIME (for tabular data) this means that LIME should be used with great care.
Furthermore, we suggest analysing the resulting explanations' stability when making use of LIME.

We think that the global sampling of LIME is responsible for many of the pitfalls identifed.
Hence, we propose that LIME should be altered in the way proposed by @laugel2018defining to LIME-K.
Local sampling should replace global sampling to better control for the locality.

Even though having said this, we think that LIME is one of the most promising contributions to the Interpretable Machine Learning community.
The problems described in this chapter are mainly associated with tabular data.
Domains where LIME has been applied successfully include image data and text data.
Within these domains, LIME works differently from tabular data.
For example, LIME's sampling for text data is already very local.
It only creates perturbations based on the instance to be explained.


## Note to the reader {#id6}


### Packages used {#id61}


For our analysis we used R (@R-base).
For all black box models we used the mlr package (@R-mlr) and the lime package (@R-lime) for the LIME explanations.
All plots have been created using @R-ggplot2.


### How we used the lime R package and why {#id62}

Using the lime package we heavily deviate from the deafult package options.
We strongly recommend to not bin numerical features.
The next chapter will outline in detail why this is a good idea.
In the first place the main argument for binning was enhanced interpretability.
We suggest, though, that the same interpretability can be obtained by the absolute contribution of the feature to the prediction.
This means instead of the local coefficient, LIME should rather print the local coefficient times the feature value within its explanation.
This arguments makes binning -- provided that there is no additional benefit except interpretability (cross reference next chapter) -- obsolete.

While we think Gower distance is an interesting approach to deal with mixed data, we explicitely promote not to use it.
In the current (July 2019) R implementation, when working with Gower distance there is no kernel applied.
Explanations do not correspond to altering the kernel width.
As we have seen, a proper kernel width may look very different depending on the associated problem.
So it is highly unlikely that a one-size-fits-all implicit kernel width always results in a proper kernel width.
In figure \@ref(fig:fig15) we analyse this statement by comparing the gower distance local coefficient to the true coefficient and the local estimates of the non-linear data simulation from section \@ref(id413).

```{r fig15, eval = TRUE, echo = FALSE, fig.align = 'center', out.width = '99%', fig.cap = "Simulated data (non-linear): Gower distance vs. Euclidean distance"}
knitr::include_graphics("images/04-09-15.png")
```

Even though we think that Gower distance may result in some cases in good local models, its (currently) lacking flexibility most likely causes either instable or global explanations.

Usually, LASSO is the preferred option for variable selection as it is less deterministic as, let's say, step-wise forward selection.
However, we do not use LASSO but step-wise forward selection because the current implementation of LASSO has shortcomings and does not deliver results suitable for our analysis.
